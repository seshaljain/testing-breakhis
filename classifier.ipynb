{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLn7vj5pDQPj"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from keras_preprocessing.image import img_to_array, load_img\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aNM0aKz1DeKy",
    "outputId": "2db7f170-59a0-43ef-e481-c78531cf4b05"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
    "# %cd \"/content/gdrive/MyDrive/Kaggle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvcsLhCQDyen"
   },
   "outputs": [],
   "source": [
    "# base_path =  '/content/gdrive/MyDrive/Kaggle/'\n",
    "base_path = '.'\n",
    "# data_path =  'BreaKHis_v1/BreaKHis_v1/histology_slides/breast'\n",
    "data_path = 'BreaKHis_v1/histology_slides/breast'\n",
    "magnifications = ['40X', '100X', '200X', '400X']\n",
    "classes = ['benign', 'malignant']\n",
    "sub_classes = {\n",
    "    'benign': ['adenosis', 'fibroadenoma', 'phyllodes_tumor', 'tubular_adenoma'],\n",
    "    'malignant': ['ductal_carcinoma', 'lobular_carcinoma', 'mucinous_carcinoma', 'papillary_carcinoma']\n",
    "}\n",
    "n_folds = (1, 2, 3, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ds_from_pickle = True\n",
    "# load_ds_from_pickle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-PYr98HAGYj6",
    "outputId": "f30660c6-3a6d-4581-d0bf-37c1dcbfbbd8"
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()\n",
    "\n",
    "if load_ds_from_pickle:\n",
    "    dataset = pd.read_pickle('dataset.pkl')\n",
    "else:\n",
    "    for clazz in classes:\n",
    "        for sub_clazz in sub_classes[clazz]:\n",
    "            path = os.path.join(base_path, data_path, clazz, \"SOB\", sub_clazz)\n",
    "            for id in os.listdir(path):\n",
    "                for magnification in magnifications:\n",
    "                    path_to_files = os.path.join(path, id, magnification)\n",
    "                    for file_name in os.listdir(path_to_files):\n",
    "                        dataset = dataset.append({\n",
    "                            'id': id,\n",
    "                            'file_name': file_name,\n",
    "                            'path': os.path.join(path_to_files, file_name),\n",
    "                            'magnification': magnification,\n",
    "                            'type': sub_clazz,\n",
    "                            'lesion': clazz\n",
    "                        }, ignore_index=True)\n",
    "\n",
    "# 5 fold K\n",
    "    n_folds = (1, 2, 3, 4, 5)\n",
    "    folds_df = pd.DataFrame()\n",
    "    for nfold in n_folds:\n",
    "        fold_file = f\"dsfold{nfold}.txt\"\n",
    "\n",
    "        fd = pd.read_csv(fold_file, delimiter=\"|\", names=[\n",
    "                         \"file_name\", \"magnification\", \"fold\", \"grp\"])\n",
    "        fd = fd[[\"file_name\", \"grp\"]]\n",
    "        fd.rename(columns={\"grp\": f\"fold_{nfold}\"}, inplace=True)\n",
    "        if folds_df.empty:\n",
    "            folds_df = folds_df.append(fd)\n",
    "        else:\n",
    "            folds_df = folds_df.merge(fd, how=\"inner\", on=\"file_name\")\n",
    "\n",
    "    folds_df.head()\n",
    "\n",
    "    dataset = dataset.merge(folds_df, how=\"inner\", on=\"file_name\")\n",
    "\n",
    "    dataset.to_pickle('dataset.pkl')\n",
    "\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "vC9oY3Tbexoa",
    "outputId": "18bd309c-e4e9-42d3-f5a8-25e3dae1b256"
   },
   "outputs": [],
   "source": [
    "def knn_clf(x_train, y_train, x_test, y_test):\n",
    "    k = 1\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=k, n_jobs=8)\n",
    "    knn_clf.fit(x_train, y_train)\n",
    "\n",
    "    return classification_report(y_test, knn_clf.predict(x_test), output_dict=True)\n",
    "\n",
    "\n",
    "def svm_clf(x_train, y_train, x_test, y_test):\n",
    "    svm_clf = SVC()\n",
    "    svm_clf = svm_clf.fit(x_train, y_train)\n",
    "\n",
    "    return classification_report(y_test, svm_clf.predict(x_test), output_dict=True)\n",
    "\n",
    "\n",
    "def dt_clf(x_train, y_train, x_test, y_test):\n",
    "    dt_clf = DecisionTreeClassifier()\n",
    "    dt_clf = dt_clf.fit(x_train, y_train)\n",
    "\n",
    "    return classification_report(y_test, dt_clf.predict(x_test), output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (460, 700, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"knn\": {\n",
    "        \"40X\": {},\n",
    "        \"100X\": {},\n",
    "        \"200X\": {},\n",
    "        \"400X\": {}\n",
    "    },\n",
    "    \"svm\": {\n",
    "        \"40X\": {},\n",
    "        \"100X\": {},\n",
    "        \"200X\": {},\n",
    "        \"400X\": {}\n",
    "    },\n",
    "    \"dt\": {\n",
    "        \"40X\": {},\n",
    "        \"100X\": {},\n",
    "        \"200X\": {},\n",
    "        \"400X\": {}\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clfs(mag, n_fold):\n",
    "    r = results\n",
    "    print(\"Magnification:\", mag)\n",
    "    print(\"Fold:\", n_fold)\n",
    "\n",
    "    df = dataset.copy()[dataset[\"magnification\"] == mag]\n",
    "    train_df = df.copy()[dataset[n_fold] == \"train\"]\n",
    "    test_df = df.copy().drop(train_df.index).reset_index(drop=True)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = [], [], [], []\n",
    "\n",
    "    for i, row in train_df.iterrows():\n",
    "        image = load_img(row[\"path\"], target_size=image_size)\n",
    "        x_train.append(img_to_array(image) / 255.0)\n",
    "        y_train.append(row[\"lesion\"])\n",
    "\n",
    "    for i, row in test_df.iterrows():\n",
    "        image = load_img(row[\"path\"], target_size=image_size)\n",
    "        x_test.append(img_to_array(image) / 255.0)\n",
    "        y_test.append(row[\"lesion\"])\n",
    "\n",
    "    x_train_ = np.asarray(x_train)\n",
    "    x_test_ = np.asarray(x_test)\n",
    "\n",
    "    x_train_ = np.reshape(x_train_, (len(x_train_), np.prod(image_size)))\n",
    "    x_test_ = np.reshape(x_test_, (len(x_test_), np.prod(image_size)))\n",
    "\n",
    "    y_train_ = encoder.transform(y_train)\n",
    "    y_test_ = encoder.transform(y_test)\n",
    "\n",
    "    r[\"knn\"][mag][n_fold] = knn_clf(\n",
    "        x_train_, y_train_, x_test_, y_test_)\n",
    "    r[\"svm\"][mag][n_fold] = svm_clf(\n",
    "            x_train_, y_train_, x_test_, y_test_)\n",
    "    r[\"dt\"][mag][n_fold] = dt_clf(\n",
    "            x_train_, y_train_, x_test_, y_test_)\n",
    "\n",
    "    print(\"Processed:\", mag, n_fold)\n",
    "\n",
    "    with open(f\"results/{mag}_{n_fold}.pkl\", 'wb') as f:\n",
    "        pickle.dump(r, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mag in magnifications:\n",
    "    for fold in n_folds:\n",
    "        run_clfs(mag=mag, n_fold=f\"fold_{fold}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.15 ('breakhis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "fa800415c0997e7abb68b5b1ecaadb87e00eb1306323784c07d0b40ffd0dcaac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
